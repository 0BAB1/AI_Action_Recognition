{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple YOLO inference : LAB 1 Bonus\n",
    "\n",
    "> This lab is meant to run locally, prefered on a windows machine because we'll use the OpenCV library\n",
    "\n",
    "In this LAB 1  Bonus we will :\n",
    "\n",
    "- Run YOLOv8 inference\n",
    "- you can also run inference on your webcam if you run this notbook on windows\n",
    "- We will also run inference on crime dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade torch torchvision\n",
    "%pip install --upgrade ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple inference tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import ultralytics\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "print(f\"Ultralytics version: {ultralytics.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load pretrained nano version \n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "def detect_objects(image_path):\n",
    "    # Run inference\n",
    "    results = model(image_path)\n",
    "    \n",
    "    # Process results\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Bounding box objects\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]  #(top, left, bottom, right)\n",
    "            \n",
    "            # Get confidence\n",
    "            confidence = box.conf[0]\n",
    "            \n",
    "            # Get class name\n",
    "            class_id = int(box.cls[0])\n",
    "            class_name = result.names[class_id]\n",
    "            \n",
    "            print(f'Detected {class_name} with confidence {confidence:.2f} at location {x1:.0f}, {y1:.0f}, {x2:.0f}, {y2:.0f}')\n",
    "\n",
    "# Example usage\n",
    "image_path = 'test.jpg'  # Replace with your image path\n",
    "detect_objects(image_path)\n",
    "\n",
    "# For webcam/video:\n",
    "# results = model.predict(source=\"0\", show=True)  # 0 for webcam if you run on windows\n",
    "# results = model.predict(source=\"video.mp4\", show=True)  # for video file\n",
    "# results = model.predict(source=\"test.jpg\", show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference on DDCASS\n",
    "\n",
    "1. Download the dataset from kaggle here : [Kaggle DCSASS link](https://www.kaggle.com/datasets/mateohervas/dcsass-dataset?resource=download)\n",
    "2. Unzip it in the current directory, we'll onyl use the \"*shoplifting*\" folder for our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load the YOLO Pose model\n",
    "model = YOLO('yolov8n-pose.pt')  # Use the pose-specific YOLO model\n",
    "\n",
    "# Path to the DCSASS Shoplifting directory\n",
    "dcsass_path = \"./DCSASS/Shoplifting\"\n",
    "\n",
    "# Iterate through directories and files\n",
    "for folder in os.listdir(dcsass_path):\n",
    "    folder_path = os.path.join(dcsass_path, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file in os.listdir(folder_path):\n",
    "            video_path = os.path.join(folder_path, file)\n",
    "            \n",
    "            # Perform pose detection\n",
    "            results = model.predict(source=video_path, show=True)\n",
    "            \n",
    "            # Access and process the pose results\n",
    "            for result in results:\n",
    "                keypoints = result.keypoints  # Get the keypoints for each detected person\n",
    "                print(f\"Keypoints for frame: {keypoints}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
